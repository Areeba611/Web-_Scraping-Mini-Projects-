{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6e7fdae-e4fb-4a7c-9bf7-a2d59b45b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DAWN NEWS HEADLINE \n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      " Source URL     : https://www.dawn.com/\n",
      " Total Headlines Scraped : 127\n",
      " Saved File     : quotes.csv\n",
      "\n",
      " Top 5 Headlines:\n",
      "--------------------\n",
      "1. PM Shehbaz announces Rs4bn for mapping damage, reconstruction of GB after floods\n",
      "2. Israeli forces kill 2 Palestinians waiting for aid in central Gaza: Red Crescent\n",
      "3. Tekken GOAT Arslan Ash bags 6th EVO title at Las Vegas showdown against fellow Pakistani Atif Butt\n",
      "4. Russia urges caution in nuclear ‘rhetoric’ after Trump comments\n",
      "5. Pakistan issues another tender to buy 0.1m tonnes of sugar, traders say\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      " Scraping Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.dawn.com/\"\n",
    "\n",
    "# Add User-Agent to avoid blocking\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "headlines = soup.find_all(\"h2\", class_=\"story__title\")\n",
    "\n",
    "# Store data in list\n",
    "headline_list = []\n",
    "\n",
    "for h in headlines:\n",
    "    headline_list.append(h.text.strip())\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame({\"Headline\": headline_list})\n",
    "df.to_csv(\"dawn_headlines.csv\", index=False, encoding='utf-8')\n",
    "print(\"\\n DAWN NEWS HEADLINE \")\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "print(f\" Source URL     : {url}\")\n",
    "print(f\" Total Headlines Scraped : {len(headline_list)}\")\n",
    "print(f\" Saved File     : {filename}\")\n",
    "\n",
    "print(\"\\n Top 5 Headlines:\")\n",
    "print(\"--------------------\")\n",
    "for i, headline in enumerate(headline_list[:5], start=1):\n",
    "    print(f\"{i}. {headline}\")\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "print(\"\\n Scraping Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a311d-78a4-47ce-a314-c0a3cb2e4283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
